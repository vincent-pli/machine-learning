{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "-Titanic.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/vincent-pli/machine-learning/blob/master/_Titanic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kyabAyOlxFxa",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c5b272a9-9e7b-455d-8eb0-263bf91a0740"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "with open(\"test.csv\", 'w') as f:\n",
        "  f.write(uploaded[uploaded.keys()[0]])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1a0ff9a2-a3a4-4934-86ae-6cbf95adcd26\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1a0ff9a2-a3a4-4934-86ae-6cbf95adcd26\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test.csv to test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lJ4JggVR1Wjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLNavL521Xqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8571
        },
        "outputId": "b47485b7-8049-4fae-ff09-802faae963ba"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('train.csv')\n",
        "cols = df.columns.tolist()\n",
        "\n",
        "cols.insert(len(df.columns)-1, cols.pop(cols.index('Survived')))\n",
        "df = df.reindex(columns=cols)\n",
        "\n",
        "def transfer_sex(x):\n",
        "  return 0 if(x=='female') else 1\n",
        "\n",
        "def transfer_city(x):\n",
        "  if(x=='C'):\n",
        "    return 0\n",
        "  elif(x=='Q'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 2\n",
        "\n",
        "def parse_cabin(x):\n",
        "  return x.split(' ')[0][0]\n",
        "  \n",
        "def transfer_cabin(x):\n",
        "  switcher = {\n",
        "      'A': 0,\n",
        "      'B': 1,\n",
        "      'C': 2,\n",
        "      'D': 3,\n",
        "      'E': 4,\n",
        "      'F': 5,\n",
        "      'G': 6\n",
        "  }\n",
        "  res = switcher.get(x, 7)\n",
        "  return res\n",
        "\n",
        "def transfer_name(x):    \n",
        "  if(x.find('Master') != -1):\n",
        "    return 0\n",
        "  elif(x.find('Mrs') != -1):\n",
        "    return 1\n",
        "  elif(x.find('Mr') != -1):\n",
        "    return 2\n",
        "  elif(x.find('Miss') != -1):\n",
        "    return 3\n",
        "  else:\n",
        "    return 4\n",
        "\n",
        "def transfer_role(x):\n",
        "  if(x['Parch'] != 0):\n",
        "    if(x['Age'] > 30):\n",
        "      if(x['Sex'] == 'male'):\n",
        "        x['Parch'] = 0   # father\n",
        "      else:\n",
        "        x['Parch'] = 1   # mather\n",
        "    else:\n",
        "      x['Parch'] = 2    # child\n",
        "  else:\n",
        "    x['Parch'] = 3  #no parents or kids on broad\n",
        "    \n",
        "  return x\n",
        "  \n",
        "  \n",
        "  \n",
        "df = df.drop(['PassengerId', 'Ticket', 'Embarked'], axis=1)\n",
        "\n",
        "\n",
        "#df = df.astype('float64')\n",
        "df = df.fillna({'Age': 20})\n",
        "df = df.fillna({'Cabin': 'F0'})\n",
        "\n",
        "df = df.apply(transfer_role, 1)\n",
        "df['Sex'] = df['Sex'].apply(transfer_sex, 1)\n",
        "# df['Embarked'] = df['Embarked'].apply(transfer_city, 1)\n",
        "df['Cabin'] = df['Cabin'].apply(parse_cabin, 1)\n",
        "df['Cabin'] = df['Cabin'].apply(transfer_cabin, 1)\n",
        "df['Name'] = df['Name'].apply(transfer_name, 1)\n",
        "\n",
        "# print df\n",
        "# return\n",
        "features = df.iloc[:, :8].values\n",
        "labels = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "labels = labelencoder.fit_transform(labels)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.2, random_state = 42)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))\n",
        "\n",
        "classifier.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'mean_absolute_error', metrics = ['accuracy'])\n",
        "\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 250)\n",
        "\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "cm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "712/712 [==============================] - 1s 1ms/step - loss: 0.4982 - acc: 0.6250\n",
            "Epoch 2/250\n",
            "712/712 [==============================] - 0s 244us/step - loss: 0.4873 - acc: 0.6475\n",
            "Epoch 3/250\n",
            "712/712 [==============================] - 0s 214us/step - loss: 0.4370 - acc: 0.6475\n",
            "Epoch 4/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.3722 - acc: 0.6531\n",
            "Epoch 5/250\n",
            "712/712 [==============================] - 0s 147us/step - loss: 0.3476 - acc: 0.6770\n",
            "Epoch 6/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.3344 - acc: 0.6770\n",
            "Epoch 7/250\n",
            "712/712 [==============================] - 0s 147us/step - loss: 0.3288 - acc: 0.6798\n",
            "Epoch 8/250\n",
            "712/712 [==============================] - 0s 206us/step - loss: 0.3259 - acc: 0.6826\n",
            "Epoch 9/250\n",
            "712/712 [==============================] - 0s 199us/step - loss: 0.3227 - acc: 0.6798\n",
            "Epoch 10/250\n",
            "712/712 [==============================] - 0s 204us/step - loss: 0.3195 - acc: 0.6882\n",
            "Epoch 11/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.3166 - acc: 0.6910\n",
            "Epoch 12/250\n",
            "712/712 [==============================] - 0s 183us/step - loss: 0.3150 - acc: 0.6952\n",
            "Epoch 13/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.3131 - acc: 0.6924\n",
            "Epoch 14/250\n",
            "712/712 [==============================] - 0s 183us/step - loss: 0.3106 - acc: 0.6994\n",
            "Epoch 15/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.3091 - acc: 0.6952\n",
            "Epoch 16/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.3079 - acc: 0.6966\n",
            "Epoch 17/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.3076 - acc: 0.7008\n",
            "Epoch 18/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.3066 - acc: 0.6966\n",
            "Epoch 19/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.3058 - acc: 0.7008\n",
            "Epoch 20/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.3039 - acc: 0.7037\n",
            "Epoch 21/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.3048 - acc: 0.7037\n",
            "Epoch 22/250\n",
            "360/712 [==============>...............] - ETA: 0s - loss: 0.3043 - acc: 0.6972"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 172us/step - loss: 0.3023 - acc: 0.6994\n",
            "Epoch 23/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.3010 - acc: 0.7051\n",
            "Epoch 24/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.3000 - acc: 0.7037\n",
            "Epoch 25/250\n",
            "712/712 [==============================] - 0s 160us/step - loss: 0.3000 - acc: 0.7008\n",
            "Epoch 26/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.2982 - acc: 0.7079\n",
            "Epoch 27/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2976 - acc: 0.7065\n",
            "Epoch 28/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.2962 - acc: 0.7093\n",
            "Epoch 29/250\n",
            "712/712 [==============================] - 0s 162us/step - loss: 0.2948 - acc: 0.7121\n",
            "Epoch 30/250\n",
            "712/712 [==============================] - 0s 193us/step - loss: 0.2941 - acc: 0.7093\n",
            "Epoch 31/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.2941 - acc: 0.7107\n",
            "Epoch 32/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2929 - acc: 0.7107\n",
            "Epoch 33/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.2921 - acc: 0.7093\n",
            "Epoch 34/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2900 - acc: 0.7149\n",
            "Epoch 35/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.2887 - acc: 0.7149\n",
            "Epoch 36/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2884 - acc: 0.7205\n",
            "Epoch 37/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2871 - acc: 0.7149\n",
            "Epoch 38/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.2866 - acc: 0.7163\n",
            "Epoch 39/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.2860 - acc: 0.7177\n",
            "Epoch 40/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.2828 - acc: 0.7205\n",
            "Epoch 41/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.2815 - acc: 0.7205\n",
            "Epoch 42/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.2815 - acc: 0.7149\n",
            "Epoch 43/250\n",
            "640/712 [=========================>....] - ETA: 0s - loss: 0.2804 - acc: 0.7406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 169us/step - loss: 0.2747 - acc: 0.7444\n",
            "Epoch 44/250\n",
            "712/712 [==============================] - 0s 185us/step - loss: 0.2762 - acc: 0.7177\n",
            "Epoch 45/250\n",
            "712/712 [==============================] - 0s 154us/step - loss: 0.2726 - acc: 0.7430\n",
            "Epoch 46/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2672 - acc: 0.7331\n",
            "Epoch 47/250\n",
            "712/712 [==============================] - 0s 186us/step - loss: 0.2630 - acc: 0.7486\n",
            "Epoch 48/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.2575 - acc: 0.7556\n",
            "Epoch 49/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2553 - acc: 0.7626\n",
            "Epoch 50/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2503 - acc: 0.7697\n",
            "Epoch 51/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.2481 - acc: 0.7711\n",
            "Epoch 52/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.2448 - acc: 0.7697\n",
            "Epoch 53/250\n",
            "712/712 [==============================] - 0s 147us/step - loss: 0.2417 - acc: 0.7795\n",
            "Epoch 54/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2384 - acc: 0.7683\n",
            "Epoch 55/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.2312 - acc: 0.7935\n",
            "Epoch 56/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.2270 - acc: 0.7921\n",
            "Epoch 57/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2255 - acc: 0.7907\n",
            "Epoch 58/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2249 - acc: 0.7865\n",
            "Epoch 59/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.2224 - acc: 0.7879\n",
            "Epoch 60/250\n",
            "712/712 [==============================] - 0s 183us/step - loss: 0.2209 - acc: 0.7907\n",
            "Epoch 61/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2198 - acc: 0.7921\n",
            "Epoch 62/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2208 - acc: 0.7921\n",
            "Epoch 63/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2169 - acc: 0.7963\n",
            "Epoch 64/250\n",
            "680/712 [===========================>..] - ETA: 0s - loss: 0.2270 - acc: 0.7779"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 163us/step - loss: 0.2262 - acc: 0.7781\n",
            "Epoch 65/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.2221 - acc: 0.7795\n",
            "Epoch 66/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2138 - acc: 0.7949\n",
            "Epoch 67/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.2140 - acc: 0.7935\n",
            "Epoch 68/250\n",
            "712/712 [==============================] - 0s 183us/step - loss: 0.2124 - acc: 0.7992\n",
            "Epoch 69/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.2117 - acc: 0.7963\n",
            "Epoch 70/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.2147 - acc: 0.7893\n",
            "Epoch 71/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2133 - acc: 0.7963\n",
            "Epoch 72/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2185 - acc: 0.7893\n",
            "Epoch 73/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2116 - acc: 0.7935\n",
            "Epoch 74/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.2108 - acc: 0.7978\n",
            "Epoch 75/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.2081 - acc: 0.7935\n",
            "Epoch 76/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.2102 - acc: 0.7949\n",
            "Epoch 77/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.2076 - acc: 0.7949\n",
            "Epoch 78/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2093 - acc: 0.7921\n",
            "Epoch 79/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.2107 - acc: 0.7963\n",
            "Epoch 80/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.2074 - acc: 0.8006\n",
            "Epoch 81/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2082 - acc: 0.7935\n",
            "Epoch 82/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2088 - acc: 0.7935\n",
            "Epoch 83/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.2089 - acc: 0.7963\n",
            "Epoch 84/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2071 - acc: 0.7921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 85/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.2080 - acc: 0.7992\n",
            "Epoch 86/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.2110 - acc: 0.7907\n",
            "Epoch 87/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.2068 - acc: 0.7949\n",
            "Epoch 88/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.2088 - acc: 0.7949\n",
            "Epoch 89/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2068 - acc: 0.7949\n",
            "Epoch 90/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.2067 - acc: 0.7978\n",
            "Epoch 91/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2063 - acc: 0.7992\n",
            "Epoch 92/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.2059 - acc: 0.7992\n",
            "Epoch 93/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2059 - acc: 0.7978\n",
            "Epoch 94/250\n",
            "712/712 [==============================] - 0s 178us/step - loss: 0.2089 - acc: 0.7949\n",
            "Epoch 95/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.2055 - acc: 0.7978\n",
            "Epoch 96/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.2052 - acc: 0.7992\n",
            "Epoch 97/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.2033 - acc: 0.8006\n",
            "Epoch 98/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.2061 - acc: 0.7978\n",
            "Epoch 99/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.2053 - acc: 0.7963\n",
            "Epoch 100/250\n",
            "712/712 [==============================] - 0s 181us/step - loss: 0.2053 - acc: 0.7992\n",
            "Epoch 101/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.2060 - acc: 0.7949\n",
            "Epoch 102/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.2081 - acc: 0.7963\n",
            "Epoch 103/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.2032 - acc: 0.7992\n",
            "Epoch 104/250\n",
            "712/712 [==============================] - 0s 187us/step - loss: 0.2077 - acc: 0.7921\n",
            "Epoch 105/250\n",
            "712/712 [==============================] - 0s 162us/step - loss: 0.2041 - acc: 0.7992\n",
            "Epoch 106/250\n",
            " 10/712 [..............................] - ETA: 0s - loss: 0.1104 - acc: 0.9000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 164us/step - loss: 0.2018 - acc: 0.7992\n",
            "Epoch 107/250\n",
            "712/712 [==============================] - 0s 178us/step - loss: 0.2026 - acc: 0.8020\n",
            "Epoch 108/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.2014 - acc: 0.8048\n",
            "Epoch 109/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.2010 - acc: 0.8048\n",
            "Epoch 110/250\n",
            "712/712 [==============================] - 0s 178us/step - loss: 0.2017 - acc: 0.8006\n",
            "Epoch 111/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.1982 - acc: 0.8062\n",
            "Epoch 112/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.1982 - acc: 0.8090\n",
            "Epoch 113/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.1981 - acc: 0.8104\n",
            "Epoch 114/250\n",
            "712/712 [==============================] - 0s 181us/step - loss: 0.1955 - acc: 0.8118\n",
            "Epoch 115/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1992 - acc: 0.8118\n",
            "Epoch 116/250\n",
            "712/712 [==============================] - 0s 159us/step - loss: 0.1961 - acc: 0.8090\n",
            "Epoch 117/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1957 - acc: 0.8104\n",
            "Epoch 118/250\n",
            "712/712 [==============================] - 0s 191us/step - loss: 0.1937 - acc: 0.8146\n",
            "Epoch 119/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.1948 - acc: 0.8132\n",
            "Epoch 120/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1930 - acc: 0.8146\n",
            "Epoch 121/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.1932 - acc: 0.8132\n",
            "Epoch 122/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1933 - acc: 0.8146\n",
            "Epoch 123/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1929 - acc: 0.8174\n",
            "Epoch 124/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.1910 - acc: 0.8174\n",
            "Epoch 125/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1951 - acc: 0.8118\n",
            "Epoch 126/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1900 - acc: 0.8202\n",
            "Epoch 127/250\n",
            "690/712 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.8246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 164us/step - loss: 0.1907 - acc: 0.8216\n",
            "Epoch 128/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1903 - acc: 0.8188\n",
            "Epoch 129/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1913 - acc: 0.8188\n",
            "Epoch 130/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1899 - acc: 0.8216\n",
            "Epoch 131/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1897 - acc: 0.8188\n",
            "Epoch 132/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1899 - acc: 0.8174\n",
            "Epoch 133/250\n",
            "712/712 [==============================] - 0s 161us/step - loss: 0.1873 - acc: 0.8202\n",
            "Epoch 134/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1897 - acc: 0.8160\n",
            "Epoch 135/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1934 - acc: 0.8104\n",
            "Epoch 136/250\n",
            "712/712 [==============================] - 0s 161us/step - loss: 0.1878 - acc: 0.8202\n",
            "Epoch 137/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.1919 - acc: 0.8160\n",
            "Epoch 138/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.1883 - acc: 0.8202\n",
            "Epoch 139/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.1900 - acc: 0.8174\n",
            "Epoch 140/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.1894 - acc: 0.8146\n",
            "Epoch 141/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1873 - acc: 0.8188\n",
            "Epoch 142/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1880 - acc: 0.8202\n",
            "Epoch 143/250\n",
            "712/712 [==============================] - 0s 188us/step - loss: 0.1891 - acc: 0.8188\n",
            "Epoch 144/250\n",
            "712/712 [==============================] - 0s 162us/step - loss: 0.1880 - acc: 0.8188\n",
            "Epoch 145/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1863 - acc: 0.8202\n",
            "Epoch 146/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.1887 - acc: 0.8174\n",
            "Epoch 147/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1882 - acc: 0.8174\n",
            "Epoch 148/250\n",
            "640/712 [=========================>....] - ETA: 0s - loss: 0.1864 - acc: 0.8203"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r712/712 [==============================] - 0s 173us/step - loss: 0.1859 - acc: 0.8202\n",
            "Epoch 149/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1875 - acc: 0.8202\n",
            "Epoch 150/250\n",
            "712/712 [==============================] - 0s 189us/step - loss: 0.1868 - acc: 0.8202\n",
            "Epoch 151/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1885 - acc: 0.8160\n",
            "Epoch 152/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1873 - acc: 0.8174\n",
            "Epoch 153/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1888 - acc: 0.8146\n",
            "Epoch 154/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.1866 - acc: 0.8188\n",
            "Epoch 155/250\n",
            "712/712 [==============================] - 0s 161us/step - loss: 0.1851 - acc: 0.8202\n",
            "Epoch 156/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.1858 - acc: 0.8188\n",
            "Epoch 157/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.1847 - acc: 0.8202\n",
            "Epoch 158/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.1858 - acc: 0.8202\n",
            "Epoch 159/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.1864 - acc: 0.8216\n",
            "Epoch 160/250\n",
            "712/712 [==============================] - 0s 160us/step - loss: 0.1853 - acc: 0.8216\n",
            "Epoch 161/250\n",
            "712/712 [==============================] - 0s 184us/step - loss: 0.1855 - acc: 0.8188\n",
            "Epoch 162/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.1879 - acc: 0.8174\n",
            "Epoch 163/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.1848 - acc: 0.8216\n",
            "Epoch 164/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1841 - acc: 0.8216\n",
            "Epoch 165/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.1954 - acc: 0.8118\n",
            "Epoch 166/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1853 - acc: 0.8202\n",
            "Epoch 167/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1847 - acc: 0.8188\n",
            "Epoch 168/250\n",
            "330/712 [============>.................] - ETA: 0s - loss: 0.1819 - acc: 0.8273"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 177us/step - loss: 0.1888 - acc: 0.8160\n",
            "Epoch 169/250\n",
            "712/712 [==============================] - 0s 184us/step - loss: 0.1843 - acc: 0.8230\n",
            "Epoch 170/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1834 - acc: 0.8230\n",
            "Epoch 171/250\n",
            "712/712 [==============================] - 0s 161us/step - loss: 0.1841 - acc: 0.8202\n",
            "Epoch 172/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1843 - acc: 0.8202\n",
            "Epoch 173/250\n",
            "712/712 [==============================] - 0s 188us/step - loss: 0.1857 - acc: 0.8202\n",
            "Epoch 174/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.1846 - acc: 0.8202\n",
            "Epoch 175/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1836 - acc: 0.8202\n",
            "Epoch 176/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1834 - acc: 0.8202\n",
            "Epoch 177/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1839 - acc: 0.8202\n",
            "Epoch 178/250\n",
            "712/712 [==============================] - 0s 160us/step - loss: 0.1836 - acc: 0.8188\n",
            "Epoch 179/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.1847 - acc: 0.8216\n",
            "Epoch 180/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.1868 - acc: 0.8188\n",
            "Epoch 181/250\n",
            "712/712 [==============================] - 0s 191us/step - loss: 0.1830 - acc: 0.8216\n",
            "Epoch 182/250\n",
            "712/712 [==============================] - 0s 178us/step - loss: 0.1835 - acc: 0.8230\n",
            "Epoch 183/250\n",
            "712/712 [==============================] - 0s 160us/step - loss: 0.1823 - acc: 0.8230\n",
            "Epoch 184/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1826 - acc: 0.8202\n",
            "Epoch 185/250\n",
            "712/712 [==============================] - 0s 156us/step - loss: 0.1830 - acc: 0.8230\n",
            "Epoch 186/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1864 - acc: 0.8146\n",
            "Epoch 187/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1816 - acc: 0.8230\n",
            "Epoch 188/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1835 - acc: 0.8202\n",
            "Epoch 189/250\n",
            "270/712 [==========>...................] - ETA: 0s - loss: 0.1696 - acc: 0.8333"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 176us/step - loss: 0.1822 - acc: 0.8202\n",
            "Epoch 190/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1839 - acc: 0.8202\n",
            "Epoch 191/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.1847 - acc: 0.8188\n",
            "Epoch 192/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.1824 - acc: 0.8216\n",
            "Epoch 193/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1826 - acc: 0.8216\n",
            "Epoch 194/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1848 - acc: 0.8174\n",
            "Epoch 195/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1805 - acc: 0.8216\n",
            "Epoch 196/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.1854 - acc: 0.8202\n",
            "Epoch 197/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.1840 - acc: 0.8174\n",
            "Epoch 198/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1834 - acc: 0.8188\n",
            "Epoch 199/250\n",
            "712/712 [==============================] - 0s 198us/step - loss: 0.1825 - acc: 0.8230\n",
            "Epoch 200/250\n",
            "712/712 [==============================] - 0s 172us/step - loss: 0.1829 - acc: 0.8216\n",
            "Epoch 201/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1830 - acc: 0.8188\n",
            "Epoch 202/250\n",
            "712/712 [==============================] - 0s 190us/step - loss: 0.1809 - acc: 0.8202\n",
            "Epoch 203/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.1862 - acc: 0.8132\n",
            "Epoch 204/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1874 - acc: 0.8174\n",
            "Epoch 205/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1819 - acc: 0.8230\n",
            "Epoch 206/250\n",
            "712/712 [==============================] - 0s 175us/step - loss: 0.1811 - acc: 0.8244\n",
            "Epoch 207/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1837 - acc: 0.8188\n",
            "Epoch 208/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1822 - acc: 0.8216\n",
            "Epoch 209/250\n",
            "712/712 [==============================] - 0s 177us/step - loss: 0.1834 - acc: 0.8174\n",
            "Epoch 210/250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 159us/step - loss: 0.1805 - acc: 0.8216\n",
            "Epoch 211/250\n",
            "712/712 [==============================] - 0s 186us/step - loss: 0.1865 - acc: 0.8174\n",
            "Epoch 212/250\n",
            "712/712 [==============================] - 0s 160us/step - loss: 0.1836 - acc: 0.8202\n",
            "Epoch 213/250\n",
            "712/712 [==============================] - 0s 173us/step - loss: 0.1822 - acc: 0.8202\n",
            "Epoch 214/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1820 - acc: 0.8188\n",
            "Epoch 215/250\n",
            "712/712 [==============================] - 0s 178us/step - loss: 0.1824 - acc: 0.8202\n",
            "Epoch 216/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1810 - acc: 0.8230\n",
            "Epoch 217/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1805 - acc: 0.8202\n",
            "Epoch 218/250\n",
            "712/712 [==============================] - 0s 179us/step - loss: 0.1804 - acc: 0.8216\n",
            "Epoch 219/250\n",
            "712/712 [==============================] - 0s 163us/step - loss: 0.1819 - acc: 0.8216\n",
            "Epoch 220/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.1820 - acc: 0.8202\n",
            "Epoch 221/250\n",
            "712/712 [==============================] - 0s 185us/step - loss: 0.1839 - acc: 0.8202\n",
            "Epoch 222/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.1830 - acc: 0.8188\n",
            "Epoch 223/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.1812 - acc: 0.8202\n",
            "Epoch 224/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1829 - acc: 0.8188\n",
            "Epoch 225/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.1798 - acc: 0.8230\n",
            "Epoch 226/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1819 - acc: 0.8202\n",
            "Epoch 227/250\n",
            "712/712 [==============================] - 0s 165us/step - loss: 0.1832 - acc: 0.8174\n",
            "Epoch 228/250\n",
            "712/712 [==============================] - 0s 189us/step - loss: 0.1853 - acc: 0.8174\n",
            "Epoch 229/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.1852 - acc: 0.8188\n",
            "Epoch 230/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.1809 - acc: 0.8216\n",
            "Epoch 231/250\n",
            "330/712 [============>.................] - ETA: 0s - loss: 0.2154 - acc: 0.7818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "712/712 [==============================] - 0s 188us/step - loss: 0.1830 - acc: 0.8188\n",
            "Epoch 232/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1823 - acc: 0.8188\n",
            "Epoch 233/250\n",
            "712/712 [==============================] - 0s 181us/step - loss: 0.1812 - acc: 0.8202\n",
            "Epoch 234/250\n",
            "712/712 [==============================] - 0s 168us/step - loss: 0.1833 - acc: 0.8174\n",
            "Epoch 235/250\n",
            "712/712 [==============================] - 0s 191us/step - loss: 0.1820 - acc: 0.8174\n",
            "Epoch 236/250\n",
            "712/712 [==============================] - 0s 164us/step - loss: 0.1816 - acc: 0.8202\n",
            "Epoch 237/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.1812 - acc: 0.8230\n",
            "Epoch 238/250\n",
            "712/712 [==============================] - 0s 185us/step - loss: 0.1793 - acc: 0.8244\n",
            "Epoch 239/250\n",
            "712/712 [==============================] - 0s 180us/step - loss: 0.1832 - acc: 0.8188\n",
            "Epoch 240/250\n",
            "712/712 [==============================] - 0s 182us/step - loss: 0.1847 - acc: 0.8146\n",
            "Epoch 241/250\n",
            "712/712 [==============================] - 0s 167us/step - loss: 0.1834 - acc: 0.8202\n",
            "Epoch 242/250\n",
            "712/712 [==============================] - 0s 169us/step - loss: 0.1800 - acc: 0.8230\n",
            "Epoch 243/250\n",
            "712/712 [==============================] - 0s 176us/step - loss: 0.1812 - acc: 0.8202\n",
            "Epoch 244/250\n",
            "712/712 [==============================] - 0s 174us/step - loss: 0.1805 - acc: 0.8202\n",
            "Epoch 245/250\n",
            "712/712 [==============================] - 0s 170us/step - loss: 0.1791 - acc: 0.8216\n",
            "Epoch 246/250\n",
            "712/712 [==============================] - 0s 166us/step - loss: 0.1818 - acc: 0.8202\n",
            "Epoch 247/250\n",
            "712/712 [==============================] - 0s 183us/step - loss: 0.1826 - acc: 0.8174\n",
            "Epoch 248/250\n",
            "712/712 [==============================] - 0s 158us/step - loss: 0.1804 - acc: 0.8244\n",
            "Epoch 249/250\n",
            "712/712 [==============================] - 0s 181us/step - loss: 0.1875 - acc: 0.8146\n",
            "Epoch 250/250\n",
            "712/712 [==============================] - 0s 171us/step - loss: 0.1818 - acc: 0.8216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[88, 17],\n",
              "       [18, 56]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "C78Sgd5O1imD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f43bbe31-7eaa-4da0-b920-5fa3c29397f5"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df_raw = pd.read_csv('test.csv')\n",
        "df = df_raw\n",
        "\n",
        "df = df.drop(['PassengerId', 'Ticket', 'Embarked'], axis=1)\n",
        "\n",
        "# df = df.astype('float64')\n",
        "df = df.fillna({'Age': 20})\n",
        "df = df.fillna({'Cabin': 'F0'})\n",
        "\n",
        "df = df.apply(transfer_role, 1)\n",
        "df['Sex'] = df['Sex'].apply(transfer_sex, 1)\n",
        "# df['Embarked'] = df['Embarked'].apply(transfer_city, 1)\n",
        "df['Cabin'] = df['Cabin'].apply(parse_cabin, 1)\n",
        "df['Cabin'] = df['Cabin'].apply(transfer_cabin, 1)\n",
        "df['Name'] = df['Name'].apply(transfer_name, 1)\n",
        "\n",
        "# print df\n",
        "# return\n",
        "y_pred = classifier.predict(df)\n",
        "y_pred = y_pred > 0.5\n",
        "\n",
        "d = {'PassengerId': df_raw['PassengerId'], 'Survived': y_pred[:, 0]}\n",
        "result = pd.DataFrame(data=d)\n",
        "print result[:2]\n",
        "\n",
        "def transfer_res(x):\n",
        "  return 1 if(x > 0.5) else 0\n",
        "\n",
        "result['Survived'] = result['Survived'].apply(transfer_res, 1)\n",
        "print result[:2]\n",
        "result.to_csv(\"try.csv\", index=False)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived\n",
            "0          892     False\n",
            "1          893      True\n",
            "   PassengerId  Survived\n",
            "0          892         0\n",
            "1          893         1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in greater\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z8rZ2bHjn9bT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('try.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyM_eym4Qq9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7140
        },
        "outputId": "fe051b21-c596-4215-a5da-b4194ada96d8"
      },
      "cell_type": "code",
      "source": [
        "!cat try.csv"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PassengerId,Survived\r\n",
            "892,0\r\n",
            "893,1\r\n",
            "894,0\r\n",
            "895,0\r\n",
            "896,1\r\n",
            "897,0\r\n",
            "898,1\r\n",
            "899,0\r\n",
            "900,1\r\n",
            "901,0\r\n",
            "902,0\r\n",
            "903,0\r\n",
            "904,1\r\n",
            "905,0\r\n",
            "906,1\r\n",
            "907,1\r\n",
            "908,0\r\n",
            "909,0\r\n",
            "910,1\r\n",
            "911,1\r\n",
            "912,0\r\n",
            "913,1\r\n",
            "914,1\r\n",
            "915,1\r\n",
            "916,1\r\n",
            "917,0\r\n",
            "918,1\r\n",
            "919,0\r\n",
            "920,0\r\n",
            "921,0\r\n",
            "922,0\r\n",
            "923,0\r\n",
            "924,1\r\n",
            "925,1\r\n",
            "926,0\r\n",
            "927,0\r\n",
            "928,1\r\n",
            "929,1\r\n",
            "930,0\r\n",
            "931,1\r\n",
            "932,0\r\n",
            "933,0\r\n",
            "934,0\r\n",
            "935,1\r\n",
            "936,1\r\n",
            "937,0\r\n",
            "938,0\r\n",
            "939,0\r\n",
            "940,1\r\n",
            "941,1\r\n",
            "942,0\r\n",
            "943,0\r\n",
            "944,0\r\n",
            "945,1\r\n",
            "946,0\r\n",
            "947,0\r\n",
            "948,0\r\n",
            "949,0\r\n",
            "950,0\r\n",
            "951,1\r\n",
            "952,0\r\n",
            "953,0\r\n",
            "954,0\r\n",
            "955,1\r\n",
            "956,1\r\n",
            "957,1\r\n",
            "958,1\r\n",
            "959,0\r\n",
            "960,0\r\n",
            "961,1\r\n",
            "962,1\r\n",
            "963,0\r\n",
            "964,1\r\n",
            "965,0\r\n",
            "966,1\r\n",
            "967,1\r\n",
            "968,0\r\n",
            "969,0\r\n",
            "970,0\r\n",
            "971,1\r\n",
            "972,1\r\n",
            "973,1\r\n",
            "974,0\r\n",
            "975,0\r\n",
            "976,0\r\n",
            "977,0\r\n",
            "978,1\r\n",
            "979,1\r\n",
            "980,1\r\n",
            "981,1\r\n",
            "982,1\r\n",
            "983,0\r\n",
            "984,1\r\n",
            "985,0\r\n",
            "986,0\r\n",
            "987,0\r\n",
            "988,1\r\n",
            "989,0\r\n",
            "990,1\r\n",
            "991,0\r\n",
            "992,1\r\n",
            "993,0\r\n",
            "994,0\r\n",
            "995,0\r\n",
            "996,1\r\n",
            "997,0\r\n",
            "998,0\r\n",
            "999,0\r\n",
            "1000,0\r\n",
            "1001,0\r\n",
            "1002,0\r\n",
            "1003,1\r\n",
            "1004,0\r\n",
            "1005,1\r\n",
            "1006,1\r\n",
            "1007,0\r\n",
            "1008,0\r\n",
            "1009,1\r\n",
            "1010,0\r\n",
            "1011,1\r\n",
            "1012,1\r\n",
            "1013,0\r\n",
            "1014,1\r\n",
            "1015,0\r\n",
            "1016,0\r\n",
            "1017,1\r\n",
            "1018,0\r\n",
            "1019,1\r\n",
            "1020,0\r\n",
            "1021,0\r\n",
            "1022,0\r\n",
            "1023,0\r\n",
            "1024,1\r\n",
            "1025,0\r\n",
            "1026,0\r\n",
            "1027,0\r\n",
            "1028,0\r\n",
            "1029,0\r\n",
            "1030,1\r\n",
            "1031,0\r\n",
            "1032,0\r\n",
            "1033,1\r\n",
            "1034,1\r\n",
            "1035,0\r\n",
            "1036,0\r\n",
            "1037,0\r\n",
            "1038,0\r\n",
            "1039,0\r\n",
            "1040,0\r\n",
            "1041,0\r\n",
            "1042,1\r\n",
            "1043,0\r\n",
            "1044,0\r\n",
            "1045,1\r\n",
            "1046,0\r\n",
            "1047,0\r\n",
            "1048,1\r\n",
            "1049,1\r\n",
            "1050,0\r\n",
            "1051,1\r\n",
            "1052,1\r\n",
            "1053,1\r\n",
            "1054,1\r\n",
            "1055,0\r\n",
            "1056,0\r\n",
            "1057,1\r\n",
            "1058,0\r\n",
            "1059,0\r\n",
            "1060,1\r\n",
            "1061,1\r\n",
            "1062,0\r\n",
            "1063,0\r\n",
            "1064,0\r\n",
            "1065,0\r\n",
            "1066,0\r\n",
            "1067,1\r\n",
            "1068,1\r\n",
            "1069,0\r\n",
            "1070,1\r\n",
            "1071,1\r\n",
            "1072,0\r\n",
            "1073,0\r\n",
            "1074,1\r\n",
            "1075,0\r\n",
            "1076,1\r\n",
            "1077,0\r\n",
            "1078,1\r\n",
            "1079,0\r\n",
            "1080,0\r\n",
            "1081,0\r\n",
            "1082,0\r\n",
            "1083,0\r\n",
            "1084,1\r\n",
            "1085,0\r\n",
            "1086,1\r\n",
            "1087,0\r\n",
            "1088,1\r\n",
            "1089,1\r\n",
            "1090,0\r\n",
            "1091,1\r\n",
            "1092,1\r\n",
            "1093,1\r\n",
            "1094,1\r\n",
            "1095,1\r\n",
            "1096,0\r\n",
            "1097,0\r\n",
            "1098,1\r\n",
            "1099,0\r\n",
            "1100,0\r\n",
            "1101,0\r\n",
            "1102,0\r\n",
            "1103,0\r\n",
            "1104,1\r\n",
            "1105,1\r\n",
            "1106,0\r\n",
            "1107,0\r\n",
            "1108,1\r\n",
            "1109,1\r\n",
            "1110,1\r\n",
            "1111,0\r\n",
            "1112,1\r\n",
            "1113,0\r\n",
            "1114,1\r\n",
            "1115,0\r\n",
            "1116,1\r\n",
            "1117,1\r\n",
            "1118,0\r\n",
            "1119,1\r\n",
            "1120,0\r\n",
            "1121,0\r\n",
            "1122,1\r\n",
            "1123,1\r\n",
            "1124,0\r\n",
            "1125,0\r\n",
            "1126,0\r\n",
            "1127,0\r\n",
            "1128,0\r\n",
            "1129,0\r\n",
            "1130,1\r\n",
            "1131,1\r\n",
            "1132,1\r\n",
            "1133,1\r\n",
            "1134,1\r\n",
            "1135,0\r\n",
            "1136,1\r\n",
            "1137,0\r\n",
            "1138,1\r\n",
            "1139,0\r\n",
            "1140,1\r\n",
            "1141,1\r\n",
            "1142,1\r\n",
            "1143,0\r\n",
            "1144,1\r\n",
            "1145,0\r\n",
            "1146,0\r\n",
            "1147,0\r\n",
            "1148,0\r\n",
            "1149,0\r\n",
            "1150,1\r\n",
            "1151,0\r\n",
            "1152,0\r\n",
            "1153,0\r\n",
            "1154,1\r\n",
            "1155,1\r\n",
            "1156,0\r\n",
            "1157,0\r\n",
            "1158,0\r\n",
            "1159,0\r\n",
            "1160,1\r\n",
            "1161,0\r\n",
            "1162,0\r\n",
            "1163,0\r\n",
            "1164,1\r\n",
            "1165,1\r\n",
            "1166,0\r\n",
            "1167,1\r\n",
            "1168,0\r\n",
            "1169,0\r\n",
            "1170,0\r\n",
            "1171,0\r\n",
            "1172,1\r\n",
            "1173,1\r\n",
            "1174,1\r\n",
            "1175,1\r\n",
            "1176,1\r\n",
            "1177,0\r\n",
            "1178,0\r\n",
            "1179,0\r\n",
            "1180,0\r\n",
            "1181,0\r\n",
            "1182,0\r\n",
            "1183,1\r\n",
            "1184,0\r\n",
            "1185,0\r\n",
            "1186,0\r\n",
            "1187,0\r\n",
            "1188,1\r\n",
            "1189,0\r\n",
            "1190,0\r\n",
            "1191,0\r\n",
            "1192,0\r\n",
            "1193,0\r\n",
            "1194,0\r\n",
            "1195,0\r\n",
            "1196,1\r\n",
            "1197,0\r\n",
            "1198,1\r\n",
            "1199,1\r\n",
            "1200,0\r\n",
            "1201,1\r\n",
            "1202,0\r\n",
            "1203,0\r\n",
            "1204,0\r\n",
            "1205,1\r\n",
            "1206,1\r\n",
            "1207,1\r\n",
            "1208,0\r\n",
            "1209,0\r\n",
            "1210,0\r\n",
            "1211,0\r\n",
            "1212,0\r\n",
            "1213,0\r\n",
            "1214,0\r\n",
            "1215,0\r\n",
            "1216,1\r\n",
            "1217,0\r\n",
            "1218,1\r\n",
            "1219,1\r\n",
            "1220,0\r\n",
            "1221,0\r\n",
            "1222,1\r\n",
            "1223,0\r\n",
            "1224,0\r\n",
            "1225,1\r\n",
            "1226,0\r\n",
            "1227,0\r\n",
            "1228,0\r\n",
            "1229,0\r\n",
            "1230,0\r\n",
            "1231,1\r\n",
            "1232,0\r\n",
            "1233,0\r\n",
            "1234,0\r\n",
            "1235,1\r\n",
            "1236,1\r\n",
            "1237,1\r\n",
            "1238,0\r\n",
            "1239,1\r\n",
            "1240,0\r\n",
            "1241,1\r\n",
            "1242,1\r\n",
            "1243,0\r\n",
            "1244,1\r\n",
            "1245,0\r\n",
            "1246,1\r\n",
            "1247,0\r\n",
            "1248,1\r\n",
            "1249,0\r\n",
            "1250,0\r\n",
            "1251,1\r\n",
            "1252,0\r\n",
            "1253,1\r\n",
            "1254,1\r\n",
            "1255,0\r\n",
            "1256,1\r\n",
            "1257,1\r\n",
            "1258,0\r\n",
            "1259,1\r\n",
            "1260,1\r\n",
            "1261,0\r\n",
            "1262,0\r\n",
            "1263,1\r\n",
            "1264,0\r\n",
            "1265,0\r\n",
            "1266,1\r\n",
            "1267,1\r\n",
            "1268,0\r\n",
            "1269,0\r\n",
            "1270,0\r\n",
            "1271,0\r\n",
            "1272,0\r\n",
            "1273,0\r\n",
            "1274,1\r\n",
            "1275,1\r\n",
            "1276,0\r\n",
            "1277,1\r\n",
            "1278,0\r\n",
            "1279,0\r\n",
            "1280,0\r\n",
            "1281,0\r\n",
            "1282,0\r\n",
            "1283,1\r\n",
            "1284,1\r\n",
            "1285,0\r\n",
            "1286,0\r\n",
            "1287,1\r\n",
            "1288,0\r\n",
            "1289,1\r\n",
            "1290,0\r\n",
            "1291,0\r\n",
            "1292,1\r\n",
            "1293,0\r\n",
            "1294,1\r\n",
            "1295,0\r\n",
            "1296,0\r\n",
            "1297,0\r\n",
            "1298,0\r\n",
            "1299,1\r\n",
            "1300,1\r\n",
            "1301,1\r\n",
            "1302,1\r\n",
            "1303,1\r\n",
            "1304,1\r\n",
            "1305,0\r\n",
            "1306,1\r\n",
            "1307,0\r\n",
            "1308,0\r\n",
            "1309,1\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DonaXmmtU5g1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('train.csv')\n",
        "print(df.shape)\n",
        "df = df.drop(['PassengerId', 'Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked'], axis=1)\n",
        "df = df.sort_values(by=['Pclass'])\n",
        "print df\n",
        "df.to_csv('xxx.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fPhFGtiEak_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}